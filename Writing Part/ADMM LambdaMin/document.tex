\documentclass[a4paper,11pt]{article}

\usepackage{geometry}
\geometry{left=2cm,right=2cm,top=3cm,bottom=2cm}
\usepackage{indentfirst}
\usepackage{dsfont}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage[usenames,dvipsnames]{color}
  \author{Eddie Yue} 
  \title{Eddie Yue Uchicago Master Thesis \\
         \vspace{3 mm} \large ADMM (alternating direction method of multipliers) Outline}
\pagestyle{fancy}
\fancyhf{}
\linespread{1.5}


\begin{document} 
	\paragraph{ADMM for $\lambda_{min}$}: \\
	To find the $\lambda_{min}$ with the optimization problem:
	\[
	\hat{\lambda} = \min_\Theta \|\Sigma\Theta - \mathds{1}_p\|_\infty
	\tag{1}\label{myeq1}
	\] 
	
	To make the optimization problem easier, I could split the problem \eqref{myeq1} to each colunms of $\theta$ by the property of and Inf-norm.
	\[ \hat{\lambda_i} = \min_{x_i} 
	\|\Sigma\*x_i\ - e_i\|_\infty
	\tag{2}\label{myeq2} \]
	where $x_i$ is the $i^{th}$ colunm of $\theta$ and the $e_i$ is the $i^{th}$ column of $\mathds{1}_p $. And $\lambda = \max \{\lambda_1, \lambda_2, ..., \lambda_p\}$\\
	
	We will use ADMM method to solve this optimization problem for \eqref{myeq2}.
	
	\[
	\hat{\lambda} = \min_y \|y\|_\infty
	\quad s.t \quad \Sigma{x} - v - y = 0
	\tag{3}\label{myeq3}
	\] 
	
	To turn ADMM into ou problem, set v = $e_i$. In order to describe the ADMM iterations,	then we introduce augmented Lagrangain function of problem \eqref{myeq3}:
	\[
	L_\mu(x,y,u) = \|y\|_\infty + u^T(\Sigma{x}- v - y) + \frac{\mu}{2}\|\Sigma{x}-v- y\|_{2}^2
	\tag{4}\label{myeq4}
	\]
	for some $\mu > 0$. \\

	Each iteration of the ADMM involves alternate minimization of $L_\mu$ with respect to x and y, followed by an update of u. Here is the outline for ADMM:\\
	
	Start with $y^0 , u^0 \in \mathbb{R}^p$ and $ \mu > 0$.Then iterate with x and y followed by an update of u until converge. For k = 0,1,...
	\[\left\{
	\begin{array}{lr}
	y^{k+1} = \arg\!\min_y L_\mu(x^k,y,u^k) \\
	x^{k+1} \in \arg\!\min_x L_\mu(x,y^{k+1},u^k)\\
	u^{k+1} = u^k +\mu(\Sigma{x^{k+1}}-v-y^{k+1})
	\end{array}
	\right.
	\tag{5}\label{myeq5}
	\]
	
	For the first subproblem in \eqref{myeq5} can be rewritten as:
	\begin{align*}
	y^{k+1} &= \arg\!\min_y \|y - (\Sigma{x^k}-v+\frac{u^k}{\mu})\|_{2}^2 + \|y\|_\infty\\
	y^{k+1} &= \arg\!\min_y \|y - b\| + \|y\|_\infty \quad \text{where } b = \Sigma{x^k}-v+\frac{u^k}{\mu}
	\tag{6}\label{myeq6}
	\end{align*}

	The solution y for the problem \eqref{myeq6} always be a truncated version of the vector b. Hence, I need to search through all absolute value of b. And I will find out the T produced the lowest value of \eqref{myeq6}.\\
	
	For each i = 1,...,length(b):\\
	
	1. set T = $|b_i|$\\
	
	2. Compute y with this level of T\\
	
	3. Compute the value of the objective function \eqref{myeq6}\\
	
	Then I pick the T that produce the lowest value of function \eqref{myeq6} and update y. 
	
	The second subproblem in \eqref{myeq5} is harder to solve, it can be rewritten as, 
	\[
	x^{k+1} = \arg\!\min_x \frac{\mu}{2}\|\Sigma{x}-v-y^{k+1}+\frac{u^k}{\mu}\|_{2}^2 
	\tag{7}\label{myeq7}
	\]
		
	Then we introduce a precondition on \eqref{myeq7} with $\alpha$ =  largest absolute value eigenvalue of $\Sigma$ * 1.01 and $A \in \mathbb{R}^p$ s.t $A^TA = \alpha^2\mathds{1}_p - \Sigma^T\Sigma$.
	\begin{align*}
	x^{k+1} &= \arg\!\min_x \frac{\mu}{2}\|\Sigma{x}-v-y^{k+1}+\frac{u^k}{\mu}\|_{2}^2  +\frac{\mu}{2}\|A(x-x^k)\|_{2}^2\\
	x^{k+1} &= \arg\!\min_x \frac{\mu}{2}(x^T\Sigma^T\Sigma{x} + x^TA^TA{x}-2x^T\Sigma{v} - 2x^TA^TA{x^k}) + C\\
	&\text{where } d = v +y^{k+1}-\frac{u^k}{\mu} \text{ and constant } C\\
	x^{k+1} &= \arg\!\min_x \frac{\mu\alpha^2}{2}[x^Tx-\frac{2x^T}{\alpha^2}(\Sigma{d}+A^TA{x^k})]+ C\\
	x^{k+1} &= \arg\!\min_x \frac{\mu\alpha^2}{2}\|x-\frac{\Sigma{d}+A^TA{x^k}}{\alpha^2}\|_{2}^2
	\tag{8}\label{myeq8}
	\end{align*}
	
	From the \eqref{myeq8}, it is clear that the solution of this quadratic optimization problem would be $x^{k+1} = \frac{\Sigma{v}+A^TA{x^k}}{\alpha^2}$
\end{document}
